### 操作系统


#### 历史
历史：单道（任务顺序执行）-》多道（任务顺序执行，遇到IO阻塞，切换任务） -> 时间片，每个进程每次只能执行一个时间片就切换


用户态进程 通过系统调用 


每个进程都有两个栈空间，用户栈user stack和内核栈kernel stack

用户栈：

每当进程调用一次函数，都会在用户栈中为该函数分配一个栈帧（stack frame），也称为调用栈（call stack），当该函数返回时又会释放该栈帧。

无限递归栈溢出问题

内核栈：
内核栈的作用是存放上下文切换时的进程信息。
当进程A要切换到进程B时，首先要陷入内核，然后内核将CPU中关于进程A的进程信息（即某些寄存器中的值）
保存在进程A的内核栈中，然后从进程B的内核栈中恢复进程B的信息到CPU的某些寄存器中，
再退出内核模式回到进程B，这样CPU就开始执行进程B了。



虚拟内存分页和物理内存分页，相同大小，4KB，虚拟页有一个有效位属性，代表是否有对应的物理页
从虚拟内存映射到物理内存，操作系统为每个进程维护了一个页表的数据结构
每个页表项包含虚拟页号，物理页号，页便宜，有效位，页是否可读/写/执行的保护位，页是处于内存还是存在于交换分区的存在位，页是否修改过的脏位，页是否最近访问过的访问位，等等


页面需要记录的东西很多，导致所占用的内存也很大，因此有三种解决方法：
1 分段加分页，不再对整个地址空间分配已页表，而对段落分配一个页表，这样页表就会变小。但是总的页表还是一样，没用
2 多级页表，linux方案，增加一个页目录的数据结构记录所有页表的有效状态，有效代表页表已经分配



swap分区：交换分区，将磁盘当内存使用。
在请求内存分配地址空间时，没有多余物理内存空间的时候，就会将一些不常用的数据先移动到swap分区（page in），等需要这些数据时，再移动回来(page out，算法：FIFO,LRU,RANDOM)
问题：如何将虚拟地址空间映射到磁盘swap分区上
解决：每个虚拟页有一个`存在位`表示该页是否处于内存，1是在内存，0是在交换分区

在计算机领域中，常会使用高水位线和低水位线来监视进程的一些可用性资源。当这类可用性资源的数量高于或临近高水位线的值时，表明资源充足。当可用性资源的数量已经低于低水位线，说明资源紧张，应当采取一些措施恢复一些资源。

page in和page out是拷入或拷出进程的一页或某些页
swap in和swap out是拷入或拷出进程的所有页


#### 进程间通信
1 管道

2 SOCKET

3 信号（signal）是一种处理异步事件的方式。信号时比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程外，还可以发送信号给进程本身。

4 信号量（Semaphore）进程间通信处理同步互斥的机制。是在多线程环境下使用的一种设施, 它负责协调各个线程, 以保证它们能够正确、合理的使用公共资源。


5 共享内存
底层：一个进程创建一片内存空间作为通讯用，其他进程将该片内存映射到自己的虚拟地址空间，这样进程各自读写该片内存就是在进行通信

6 消息队列


#### 进程同步
问题：锁解决了同步问题，带来了循环等待，然后发明了sleep&wakeup ,又带来了死锁，然后发明了信号量，又带来了

1 竞争
代码竞争：多个线程争相执行同一段代码
数据竞争：多个线程争相访问同一份数据

2 临界区：造成竞争的共享代码段或资源

3 互斥：一次有且只有一个线程进入临界区

4 锁：保证互斥的同步机制

5 信号量

6 管程monitor
问题：依赖编译器

7 消息传递
问题：消息丢失和身份识别

8 栅栏
概念：主要对一组线程进行协调，有时候一组进程需要系统完成一个问题，需要所有进程都到达同一个地方（在此设置栅栏）才能一起前进


#### 进程调度
目标：极小化平均响应时间，极大化系统吞吐率，保持系统各个功能部件均处于繁忙状态和提供某种貌似公平的机制

进程调度的两个关键性指标是：响应时间和周转时间。
响应时间：进程未运行到下次被选中运行的时间间隔。例如进程刚被创建到第一次调度到它的时间间隔，再例如从该进程切换走后到下次调度到该进程的时间间隔。
		  响应时间体现了交互性，响应时间越短，交互性越好。例如从键盘敲下一个字符，如果需要等待几秒钟才出现到屏幕，这个交互性是非常差的。
周转时间：进程从启动开始到执行完成所花费的时间。周转时间体现的性能，周转时间越短，说明进程从开始到完成等待的时间越短。
进程调度算法：
非抢占式
1 FCFS(first come first serve 先来先服务)：排队执行，问题是耗时长的进程排在前面将会导致后面的响应时间很长
2 SJF(shortest job first,最短任务优先)：耗时短的任务排前面先执行，问题是耗时短的任务在实际中可能还没启动，耗时长的进程先启动获得调度
抢占式
3 STCF(shortest time-to-complete first，最短完成时间优先)：假设进程是可以抢占的，那么新进程进来，比较所有进程，执行耗时最短的进程
4 RR(Round-robin 轮询算法)：STCF的优化版，时间片执行进程，问题是频繁切换上下文，增加平均周转时间

以上算法都是假设提前知道进程的耗时，解决方式是先将程序运行一遍，记录cpu使用时间，在以后的运行中，就根据该时间调度（还是有问题的，比如程序的变动又要重新记录，记录的空间存储等等）

MLFQ(Multiple-level Feedback Queue，多级反馈队列)：进程分优先级放入不同的队列，cpu从高到底调度队列中的进程，cpu密集型优先级低，IO密集型优先级高
规则1：如果A的优先级 > B的优先级，运行A
规则2：如果A的优先级 = B的优先级，轮转运行
规则3：工作进入系统时，放在最高优先级（最上层队列）
规则4：一旦工作用完了其在某一层的时候配额（无论中间主动放弃多少次CPU），就降低其优先级（移入低一级队列）
规则5：经过一段时间S，将系统中所有工作重新加入最高优先级队列

`renice`,`nice`,`ionice` Linux优先级设置命令

CFS(Complete Fair Scheduler，完全公平调度)：


* 问题：调度异常之优先级倒挂
一个低优先级任务持有一个高优先级任务认为需要的共享资源，这样高优先级任务会一直阻塞，知道低优先级任务释放该资源


#### 原语概念
第一次看到“原语”这种提法还是在学习操作系统的时候，而且要么不碰到，一碰就是一双，“PV操作”这对原语就是我最先接触到的操作系统原语。
当年 Alan Turing 在定义图灵机六个基本操作的时候也用了 primitive 这个词。当时觉得“原语”这个词很陌生，于是上网查了一下，大部分的解释都包含了“原子操作”的概念，
事实上知道原语英文（primitives）的朋友应该知道它和“atomic”并没有多大关联，这说明“原语”和“原子”都姓“原”仅仅是一个巧合，尽管所有的“原语”看上去都是原子操作，但是它的定义绝对不仅限于此。
后来我在一个外国的论坛上找到了答案，具体的说法我已经忘了，简单地讲就是“石头、剪刀、布”这三样东西，除了“石头”是原语，而“剪刀”和“布头”不算，
为什么呢？因为剪刀和布头都是人工合成的，而石头是浑然天成的。因此“原语”这个单词的定义还是要从它的英文原词 primitive 出发，也就是“原始”的意思。
我们知道物质的最小组成单位绝非原子，比原子小的是质子，比质子小的还有夸克。那么为什么我们看到一把剪刀以后很容易想到它的各个组成部分（比如锋利的部分用铁制成，而握的地方用塑料），
而看到一块石头以后，脑子里还是只有一块石头，而不是各种矿物质的名称呢?原因是在人类形成最早语言的过程中还不知道什么是矿物质，众所周知人类的视力其实是很差的，
只能看到光谱上面很小的一段可见光，也不能像显微镜一样看见的东西，直到道尔顿发现原子，人类科学才算走上了正轨。

计算机是一门人造科学，因此真正意义上的“原语”是不存在的。操作系统层面上的“原语”（比如 write 之类的系统调用）对程序员来讲的确是不可分割的最小单位，
但是这写系统调用本身还是用好几句汇编语句组成的（对于 Linux 来说是 C 语言）。可能有人要说到了机器代码这一级就不能再分了，
但事实上一条机器指令也是由好几个组合逻辑信号构成的。同样的道理，控制信号也不过是无数电子在器件内部漂移的结果。

因此定义“原语”的前提是观察者所处的位置。一旦规定了观察者的位置和观察的角度，比如就在操作系统的这层上，read，wirte，wait这些个系统调用自然就是最“原始”的词汇，
这也是为什么“原语”会在操作系统中频繁出现的缘故。

[参考链接](https://www.cnblogs.com/hualalasummer/p/3704225.html)

PV原语：荷兰语，其实是Up，Down操作，都是原子操作
P（up加法操作）:
1 将信号量的值+1（此操作将叫醒一个在该信号量上面等待的线程）
2 线程继续往下执行
V（down减法操作）：
1 判断信号量的值是否大于等于1
2 是，则-1，线程继续往下执行
2 否，在该信号量上等待（线程被挂起）


问题：
1 所有同步原语在微指令级都是有多个步骤构成，操作系统是如何保证这些同步原语的原子性呢？即在执行同步原语的中途是怎么防止别的进程或线程插入执行？
是硬件提供了一些原子操作：中断禁止和启用（interrupt enable/diable）,内存加载和存入（load/store）和测试与设置（test&set）

#### 锁
1 用中断禁止和启用（interrupt enable/diable）来实现锁
优点：原理简单，容易理解，容易实现
缺点：频繁地禁止中断可能导致重要任务处理不及时，而且要在循环中释放锁概率不大

lock
```
lock() {
	disable interrupts
	while (value != FREE) {
		enable interrupts
		//循环开启和禁止中断，在这空隙中使得拥有value为busy的进程获得cpu执行，从而完成操作重新设置value为free
		disable interrupts
	}
	value = BUSY
	enable interrupts
}
```

unlock
```
unlock() {
	disable interrupts
	value = FREE    //这个赋值语句不是原子操作，因此需要禁止中断保护
	enable interrupts
}
```

2 用测试与设置（test&set）实现锁

3 用非繁忙等待，中断禁止和启用来实现锁

4 用最少繁忙等待，测试与设置来实现锁



锁的粒度越大，阻止其它进程的可能性就越大，多进程并发的能力就越差。锁的粒度越小，阻止其它进程的可能性就越小，并发的能力就越强
锁的粒度太小也不一定好，因为每个锁都是需要额外管理的，粒度越小，需要维护的锁数量越多。比如频繁创建锁和频繁释放锁的开销并不一定小，甚至在极端的时候比维护单个粗粒度的锁效率更低

#### 死锁
场景：两个线程互相竞争对方拥有的资源才能继续执行，从而一直等待，引发死锁。
发生四个条件：
1 资源互斥，资源不能共享，一次只能由一个线程使用
2 持有等待，即一个线程在请求新的资源的时候，不会释放已拥有的资源
3 资源不能抢占
4 循环等待，即互相请求对方拥有的资源

经典问题：哲学家就餐问题

应对策略：
1 无为而治，因为防治死锁代价大，所以能不管就不管，除非是高可靠系统或实时控制系统
2 死锁出现后进行检测和修复，代价往往很大，不适用
3 动态避免：通过资源的合理分配，使系统不能进入非安全状态，从而避免死锁的发生。但是线程过多，资源复杂，计算的代价也很大
4 静态防止：消除死锁发生的四个条件

死锁，饥饿，活锁关系：
饥饿是进程获取不到资源一直等待，活锁是两个进程同时一起让出资源或一起请求资源导致双方一直都拿不到资源而无法推进
饥饿>活锁>>死锁


#### 内存管理
* 目标：
1 地址保护：一个进程不能随便访问另一个进程的地址空间
2 地址独立：程序发出的地址应与物理主存地址无关（虚拟内存）

* 虚拟内存：
1 中心思想:将物理主存扩大到便宜，大容量的磁盘上。程序通过操作系统的内存管理模块去对应的位置获取资源，其实就是做映射表

##### 页式内存管理
* 地址翻译：
1 固定加载地址：只适合单道编程

2 固定分区
物理地址 = 虚拟地址 + 程序所在区域的起始地址（又称，基址）
有效地址：基址《= 有效地址 《= 基址+程序长度
两个端值：基址和界限，分别用基址寄存器和界限寄存器保存，界限寄存器保存程序的长度

3 非固定分区

4 交换内存管理

* 问题
1 空间浪费，碎片空间无法使用
2 交换带来的空间增长优先，因为单一程序不能超过物理主存（减去操作系统部分）

* 按页分配（解决交换内存管理的碎片问题和空间限制问题）
核心是：将虚拟地址和物理主存划分相同大小的页，然后进行地址映射

* 页面更新算法
场景：访问的页面不在内存，系统就产生缺页中断，缺页中断服务负责将位于磁盘的数据加载到物理内存，如果物理内存有空间，则直接覆盖，若空间不足，则需要依靠一些算法替换掉一些不常用的空间
目标：在更新页面时，要尽量降低因替换空间而引发缺页中断的概率

公平算法：
1 随机算法
纯随机，效果并不好

2 先入先出（FIFO）算法
实现：用链表按照进去时间的先后链接起来，每次新页面进来，就淘汰链头，在链尾加
问题：先进来的页面可能是经常被访问的页面

3 第二次机会算法
基于FIFO改进，每次判断一下链头是否为被访问过的页面，如果是，则放到链尾重置，接着再从链头开始判断
问题：假如整个链表都是被访问过的页面，那仍然会回到A，死循环

4 时钟算法
使用索引（整数指针）数据结构的第二次机会算法
问题：可能也会死循环

非公平算法
1 最优页面更换算法
标准：选择一个再也不会被访问的页面进行替换，如果不存在这样的页面，则选最长时间不会被访问的页面替换
问题：这个只是理想，现实是不会知道页面什么时候才被访问

2 NRU算法（Not Recently Used）最近未使用算法
概念：选择一个在最近一段时间没有被访问过的页面进行替换，
实现：利用页面的访问和修改位判断，四种状态（1未访问未修改 2未访问只修改 3访问未修改 4访问并修改  ），之所以会出现未访问修改是因为系统会定期去重置访问位
	  NRU就按照1,2,3,4的顺序去替换

3 LRU算法（Least Recently Used）最近最少使用
概念：LRU的优化，不仅看是否使用过，还要看使用频率
实现：在页表记录项增加一个计数域，每次访问+1，那每次找到最小的计数域的页进行替换就行
问题：时间和空间都消耗比较大，要记录频率，也要在访问时进行更新操作；只是实现最少，没定义最近；此外计数域有空间上限，溢出后重置为0，此时的计数域最小其实是最多访问的页


4 工作集算法

混合算法
1 工作集时钟算法 （商业系统通用方案）

##### 段式内存管理
* 页式内存的缺点


#### 文件原理
* 文件系统需要达到的目标
1 地址保护
2 地址独立


### IO原理

















